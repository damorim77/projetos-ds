{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo para quebra de Captchas simples\n",
    "\n",
    "Modelo de rede neural convolucional (CNN) em Keras que consegue realizar a resolução de captchas do tipo abaixo:\n",
    "\n",
    "![Captcha](https://i.screenshot.net/yoperf2)\n",
    "\n",
    "O modelo foi treinado com base em **1.177 captchas** resolvidos manualmente, que compuseram um total de **7.062 letras/digitos** (média de 100 exemplares por letra/digito)\n",
    "\n",
    "Como as posições das letras são fixas, é possível quebrar a imagem em 6 letras, e realizar a previsão de cada uma individualmente:\n",
    "\n",
    "![Captcha separado](https://i.screenshot.net/y1vopho)\n",
    "\n",
    "----\n",
    "[Link](http://danilo-amorim.000webhost.com/files/captcha_app/base_captcha.zip) para download da base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTE 1 - TREINAMENTO DO MODELO\n",
    "\n",
    "## Importações e definições de caminhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard, CSVLogger\n",
    "from keras.preprocessing import image\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "LETRA_DIM = ( 29 , 34 )\n",
    "CUTPOINT = {\n",
    "\t\"top\"  : 7 ,\n",
    "\t\"left\" : [ 10 , 36 , 66 , 96 , 126 , 152 ]\n",
    "}\n",
    "\n",
    "ROOT = \"C:/projetos/captcha_dev/mei/dataset/\"\n",
    "\n",
    "train_path = ROOT + \"train\"\n",
    "valid_path = ROOT + \"validation\"\n",
    "test_path  = ROOT + \"test\"\n",
    "log_path  = ROOT + \"logs\"\n",
    "prediction_path = ROOT + \"prediction\"\n",
    "log_file = log_path + \"/cnn_training.log\"\n",
    "model_weights_file  = ROOT + \"cnn_weights.h5\"\n",
    "model_structure_file  = ROOT + \"cnn_model.json\"\n",
    "model_index_file  = ROOT + \"cnn_class_index.json\"\n",
    "\n",
    "captcha_file = \"C:/projetos/captcha_app/mei/base_captchas/1aours.png\"\n",
    "letra_template = prediction_path + \"/captcha_{ix}.png\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construção do modelo, ou carregamento de modelo existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando modelo\n",
      "Modelo carregado\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    cnn = Sequential()\n",
    "\n",
    "    cnn.add(Conv2D(32, (3,3), input_shape = (29, 34, 1), activation = 'relu'))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "    cnn.add(Conv2D(32, (3,3), input_shape = (29, 34, 1), activation = 'relu'))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "    cnn.add(Flatten())\n",
    "\n",
    "    cnn.add(Dense(units = 256, activation = 'relu'))\n",
    "    cnn.add(Dropout(0.4))\n",
    "    cnn.add(Dense(units = 62, activation = 'relu'))\n",
    "    cnn.add(Dropout(0.4))\n",
    "\n",
    "    cnn.add(Dense(units = 62, activation = 'softmax'))\n",
    "\n",
    "    cnn.compile( optimizer = 'adam'\n",
    "               , loss = 'categorical_crossentropy'\n",
    "               , metrics = ['accuracy'])\n",
    "    \n",
    "    return cnn\n",
    "\n",
    "def load_model():\n",
    "    model = model_from_json(open(model_structure_file).read())\n",
    "    model.load_weights(model_weights_file)\n",
    "    model.compile(  optimizer = 'adam'\n",
    "                  , loss = 'categorical_crossentropy'\n",
    "                  , metrics = ['accuracy'] )\n",
    "    return model\n",
    "\n",
    "def save_model(model):    \n",
    "    json_string = model.to_json()\n",
    "    open(model_structure_file, 'w').write(json_string)\n",
    "    model.save_weights(model_weights_file, overwrite=True)\n",
    "\n",
    "try:\n",
    "    print(\"Carregando modelo\")\n",
    "#     cnn = build_model()\n",
    "    cnn = load_model()\n",
    "    print(\"Modelo carregado\")\n",
    "except Exception as ex:\n",
    "    print(\"Erro ao carregar : \\n\" + str(ex) +  \"\\nConstruindo modelo\")\n",
    "    cnn = build_model()\n",
    "    print(\"Modelo construído\")\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura das imagens separadas nos diretórios de treino, validação e teste\n",
    "\n",
    "Utilizamos a classe ImageDataGenerator do Keras para facilitar a leitura dos diretórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4519 images belonging to 62 classes.\n",
      "Found 1138 images belonging to 62 classes.\n",
      "Found 1413 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen, test_gen, valid_gen = ImageDataGenerator(), ImageDataGenerator(), ImageDataGenerator()\n",
    "\n",
    "base_train = train_gen.flow_from_directory( train_path\n",
    "                                          , target_size = (29, 34)\n",
    "                                          , batch_size = 32\n",
    "                                          , color_mode = 'grayscale'\n",
    "                                          , class_mode = 'categorical'\n",
    "                                          , shuffle = False\n",
    "                                          , seed = 10 )\n",
    "\n",
    "base_valid = valid_gen.flow_from_directory( valid_path\n",
    "                                          , target_size = (29, 34)\n",
    "                                          , batch_size = 32\n",
    "                                          , color_mode = 'grayscale'\n",
    "                                          , class_mode = 'categorical'\n",
    "                                          , shuffle = False\n",
    "                                          , seed = 10 )\n",
    "\n",
    "base_test  = test_gen.flow_from_directory(  test_path\n",
    "                                          , target_size = (29,34)\n",
    "                                          , batch_size = 1\n",
    "                                          , color_mode = 'grayscale'\n",
    "                                          , class_mode = None\n",
    "                                          , shuffle = False\n",
    "                                          , seed = 10 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição de callbacks e fit do modelo\n",
    "\n",
    "Os callbacks realizam as seguintes funções:\n",
    "* EarlyStopping: para o treinamento caso não haja melhora na função de perda por N época\n",
    "* ReduceLROnPlateau: reduz o learning rate do modelo quando a função de perda estiver próxima da estagnação\n",
    "* ModelCheckpoint: salva progresso  do treinamento\n",
    "* Tensorboard: permite acompanhamento do treinamento pela ferramenta Tensorboard\n",
    "* CSVLogger: grava log do treinamento em csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "141/141 [==============================] - 21s 151ms/step - loss: 0.0540 - acc: 0.9840 - val_loss: 0.7519 - val_acc: 0.8879\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.05434, saving model to C:/projetos/captcha_dev/mei/dataset/cnn_weights.h5\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 20s 144ms/step - loss: 0.0506 - acc: 0.9852 - val_loss: 0.7821 - val_acc: 0.8888\n",
      "\n",
      "Epoch 00002: loss improved from 0.05434 to 0.05090, saving model to C:/projetos/captcha_dev/mei/dataset/cnn_weights.h5\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 21s 147ms/step - loss: 0.0611 - acc: 0.9816 - val_loss: 0.7600 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.05090\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 20s 139ms/step - loss: 0.0513 - acc: 0.9845 - val_loss: 0.8000 - val_acc: 0.8852\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.05090\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 19s 137ms/step - loss: 0.0529 - acc: 0.9856 - val_loss: 0.8030 - val_acc: 0.8852\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.05090\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 19s 135ms/step - loss: 0.0623 - acc: 0.9798 - val_loss: 0.7762 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.05090\n",
      "Epoch 7/10\n",
      "141/141 [==============================] - 20s 143ms/step - loss: 0.0515 - acc: 0.9856 - val_loss: 0.8149 - val_acc: 0.8834\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.05090\n",
      "Epoch 8/10\n",
      "141/141 [==============================] - 20s 139ms/step - loss: 0.0545 - acc: 0.9843 - val_loss: 0.8151 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.05090\n",
      "Epoch 9/10\n",
      "141/141 [==============================] - 20s 144ms/step - loss: 0.0586 - acc: 0.9834 - val_loss: 0.8070 - val_acc: 0.8852\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.05090\n",
      "Epoch 10/10\n",
      "141/141 [==============================] - 19s 138ms/step - loss: 0.0475 - acc: 0.9843 - val_loss: 0.8192 - val_acc: 0.8816\n",
      "\n",
      "Epoch 00010: loss improved from 0.05090 to 0.04767, saving model to C:/projetos/captcha_dev/mei/dataset/cnn_weights.h5\n"
     ]
    }
   ],
   "source": [
    "steps_train = base_train.n // base_train.batch_size\n",
    "steps_valid = base_valid.n // base_valid.batch_size\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping( monitor = 'loss'\n",
    "                 , min_delta = 1e-3\n",
    "                 , patience = 20\n",
    "                 , verbose = 1 )\n",
    "    ,\n",
    "    ReduceLROnPlateau( monitor = 'loss'\n",
    "                     , factor = 0.2\n",
    "                     , patience = 5\n",
    "                     , verbose = 1 )\n",
    "    ,\n",
    "    ModelCheckpoint( filepath = model_weights_path\n",
    "                   , monitor = 'loss'\n",
    "                   , save_best_only = True\n",
    "                   , verbose = 1 )\n",
    "    ,\n",
    "    TensorBoard( log_dir=\"{path}/{time}\" \\\n",
    "                    .format( path = log_path\n",
    "                           , time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") ) )\n",
    "    ,\n",
    "    CSVLogger(log_file)\n",
    "]\n",
    "\n",
    "cnn.fit_generator( generator = base_train\n",
    "                 , steps_per_epoch = steps_train \n",
    "                 , validation_data = base_valid\n",
    "                 , validation_steps = steps_valid\n",
    "                 , epochs = 100\n",
    "                 , callbacks = callbacks )\n",
    "\n",
    "save_model(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7596725955812654, 0.888788426547542]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate_generator( generator = base_valid\n",
    "                      , steps = steps_valid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realiza previsões na base de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1413/1413 [==============================] - 9s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "steps_test = base_test.n // base_test.batch_size\n",
    "\n",
    "base_test.reset()\n",
    "\n",
    "pred = cnn.predict_generator( base_test\n",
    "                            , steps = steps_test \n",
    "                            , verbose = 1)\n",
    "\n",
    "predicted_class_indices = np.argmax(pred,axis=1)\n",
    "\n",
    "labels = (base_train.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "res = list( map (lambda x: (x[0][0] , x[1][-5] ) , list( zip( predictions , base_test.filenames ) )) )\n",
    "\n",
    "acertos = list(filter(lambda x : x[0].lower() == x[1].lower() , res ))\n",
    "\n",
    "print(\"Acc: \" +  str(len(acertos)/len(res)) + \" |  Acertos: \" + str(len(acertos)) + \" de \" + str(len(res))  )\n",
    "pprint( res  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTE 2 : Previsão em uma nova imagem\n",
    "\n",
    "## Leitura da imagem e quebra em letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images belonging to 1 classes.\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "[ 4  1 53  6 10 51]\n",
      "{'0_min': 0, '1_min': 1, '2_min': 2, '3_min': 3, '4_min': 4, '5_min': 5, '6_min': 6, '7_min': 7, '8_min': 8, '9_min': 9, 'A_mai': 10, 'B_mai': 11, 'C_mai': 12, 'D_mai': 13, 'E_mai': 14, 'F_mai': 15, 'G_mai': 16, 'H_mai': 17, 'I_mai': 18, 'J_mai': 19, 'K_mai': 20, 'L_mai': 21, 'M_mai': 22, 'N_mai': 23, 'O_mai': 24, 'P_mai': 25, 'Q_mai': 26, 'R_mai': 27, 'S_mai': 28, 'T_mai': 29, 'U_mai': 30, 'V_mai': 31, 'W_mai': 32, 'X_mai': 33, 'Y_mai': 34, 'Z_mai': 35, 'a_min': 36, 'b_min': 37, 'c_min': 38, 'd_min': 39, 'e_min': 40, 'f_min': 41, 'g_min': 42, 'h_min': 43, 'i_min': 44, 'j_min': 45, 'k_min': 46, 'l_min': 47, 'm_min': 48, 'n_min': 49, 'o_min': 50, 'p_min': 51, 'q_min': 52, 'r_min': 53, 's_min': 54, 't_min': 55, 'u_min': 56, 'v_min': 57, 'w_min': 58, 'x_min': 59, 'y_min': 60, 'z_min': 61}\n",
      "41r6Ap\n"
     ]
    }
   ],
   "source": [
    "captcha_img = Image.open(captcha_file)\n",
    "\n",
    "for i in range(6):\t\t\t  \n",
    "    captcha_img.crop(( \n",
    "\t\t\tCUTPOINT[\"left\"][i] , \n",
    "\t\t\tCUTPOINT[\"top\"] , \n",
    "\t\t\tCUTPOINT[\"left\"][i] + LETRA_DIM[0] , \n",
    "\t\t\tCUTPOINT[\"top\"] + LETRA_DIM[1] )\n",
    "\t\t) \\\n",
    "\t\t.save(letra_template.format(ix=str(i)))\n",
    "\n",
    "base_test  = test_gen \\\n",
    "    .flow_from_directory(  prediction_path\n",
    "                          , target_size = (29,34)\n",
    "                          , batch_size = 6\n",
    "                          , color_mode = 'grayscale'\n",
    "                          , class_mode = None\n",
    "                          , shuffle = False\n",
    "                          , seed = 10 )\n",
    "\n",
    "base_test.reset()\n",
    "\n",
    "pred = cnn.predict_generator( base_test\n",
    "                            , steps = 1 \n",
    "                            , verbose = 1)\n",
    "\n",
    "predicted_class_indices = np.argmax(pred,axis=1)\n",
    "\n",
    "labels = (base_train.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [ labels[k][0] for k in predicted_class_indices ]\n",
    "\n",
    "predictions = \"\".join( predictions )\n",
    "\n",
    "print ( predictions )\n",
    "\n",
    "# Apaga imagens das letras\n",
    "for i in range(6):\n",
    "    os.unlink(letra_template.format(ix=str(i)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
